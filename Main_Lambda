import requests
import os
import openai
from dotenv import load_dotenv
import json
from openai import OpenAI

# Load the environment variables from the .env file
load_dotenv()

# Set the OpenAI API key from the environment variable
openai.api_key = ""
client = openai.OpenAI(api_key="")

def lambda_handler(event, context):
    # Parse the incoming JSON payload
    if 'body' in event:
        body = json.loads(event['body'])
        ticket_number = body.get('ticket_number')
        if ticket_number is None:
            return {
                'statusCode': 400,
                'body': json.dumps('No ticket_number provided.')
            }
    else:
        return {
            'statusCode': 400,
            'body': json.dumps('No ticket_number provided in the request body.')
        }

    global_gpt_reply = "test"
    #ticket_number = 2712
    print("The ticket number is", ticket_number)

    # Create a session and authenticate with basic auth
    session = requests.Session()
    session.headers = {
        'Authorization': ''
    }

    # Make a GET request to retrieve the ticket details
    response = session.get(f'http://centralsupportdesk1657134016.zendesk.com/api/v2/tickets/{ticket_number}/side_conversations')

    # Check if the request was successful
    if response.status_code == 200:
        ticket_data = response.json()
        sc_list = json.dumps(ticket_data['side_conversations'], indent=4)
        to_mail_one = ticket_data["side_conversations"][0]["participants"][0]["email"]
        to_mail_two = ticket_data["side_conversations"][0]["participants"][1]["email"]
        sc_id = ticket_data['side_conversations'][0]['id']

        # Get the current directory
        current_dir = os.path.dirname(os.path.abspath(__file__))

        # Construct the relative path to the file
        filepath = os.path.join(current_dir, "GPT_Prompt_02.txt")

        # Read the file
        with open(filepath, 'r') as file:
            prompt = file.read().replace("print(sc_list)", sc_list)
            gptresponse = client.chat.completions.create(
                model="gpt-4",
                messages=[
                    {"role": "system", "content": "You are a helpful assistant."},
                    {"role": "user", "content": prompt}  # Assuming you want the entire file content as the user's prompt
                    ],
                max_tokens=100
            )
            global_gpt_reply = gptresponse.choices[0].message.content
            print(global_gpt_reply)
        print(global_gpt_reply)

        # Send the reply to the side conversation on ticket
        if "sc_esc tag" not in global_gpt_reply:
            headers = {
                "Content-Type": "application/json",
                "Authorization" : ""
            }

            jsonBody = {
                "message": {
                    "body": global_gpt_reply,
                    "to": [
                        { "email": to_mail_two }
                    ]
                }
            }

            response = requests.request(
                "POST",
                f"https://centralsupportdesk1657134016.zendesk.com/api/v2/tickets/{ticket_number}/side_conversations/{sc_id}/reply",
                headers=headers,
                data=json.dumps(jsonBody)
            )

        print(response.status_code)

    return {
        'statusCode': 200,
        'body': json.dumps('Lambda function executed successfully!')
    }

# Assuming this is for demonstration purposes outside AWS Lambda
if __name__ == "__main__":
    event = {}
    context = {}
    lambda_handler(event, context)
